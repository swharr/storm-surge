apiVersion: v1
kind: ConfigMap
metadata:
  name: feature-flag-config
  namespace: oceansurge
data:
  FEATURE_FLAG_PROVIDER: "launchdarkly"
  LOGGING_PROVIDER: "auto"
  COST_IMPACT_THRESHOLD: "0.05"
  SPOT_CLUSTER_ID: "ocn-12345678"
  WEBHOOK_ENDPOINT: "/webhook/launchdarkly"
  API_ENDPOINT: "/api/cluster/status"
  LOG_LEVEL: "INFO"

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: middleware-code
  namespace: oceansurge
data:
  main.py: |
    #!/usr/bin/env python3
    """
    OceanSurge Middleware: Feature Flag to Spot API Integration
    Handles feature flag webhook notifications and triggers Spot API actions
    Supports LaunchDarkly and Statsig providers
    """

    import os
    import json
    import logging
    import requests
    from flask import Flask, request, jsonify
    from typing import Dict, Any
    import time
    import atexit
    from feature_flags import FeatureFlagManager
    from logging_providers import LoggingManager

    # Configure logging
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)

    app = Flask(__name__)

    # Configuration from environment variables
    FEATURE_FLAG_PROVIDER = os.getenv('FEATURE_FLAG_PROVIDER', 'launchdarkly')
    LOGGING_PROVIDER = os.getenv('LOGGING_PROVIDER', 'auto')
    SPOT_API_TOKEN = os.getenv('SPOT_API_TOKEN', '')
    COST_IMPACT_THRESHOLD = float(os.getenv('COST_IMPACT_THRESHOLD', '0.05'))

    # Spot API configuration
    SPOT_API_BASE_URL = "https://api.spotinst.io/ocean/k8s"
    SPOT_CLUSTER_ID = os.getenv('SPOT_CLUSTER_ID', '')

    # Initialize feature flag manager
    try:
        flag_manager = FeatureFlagManager(FEATURE_FLAG_PROVIDER)
        logger.info(f"Initialized feature flag provider: {FEATURE_FLAG_PROVIDER}")
    except ValueError as e:
        logger.error(f"Failed to initialize feature flag provider: {e}")
        exit(1)

    # Initialize logging manager
    try:
        logging_manager = LoggingManager(LOGGING_PROVIDER, FEATURE_FLAG_PROVIDER)
        logger.info(f"Initialized logging provider: {logging_manager.get_provider_type()}")
    except Exception as e:
        logger.error(f"Failed to initialize logging provider: {e}")
        logging_manager = None

    # Register cleanup function to flush events on shutdown
    def cleanup():
        if logging_manager:
            logging_manager.flush_events()
            logger.info("Flushed pending events on shutdown")

    atexit.register(cleanup)


    class SpotOceanManager:
        """Handles Spot Ocean API interactions"""

        def __init__(self, api_token: str, cluster_id: str):
            self.api_token = api_token
            self.cluster_id = cluster_id
            self.headers = {
                'Authorization': f'Bearer {api_token}',
                'Content-Type': 'application/json'
            }

        def get_cluster_info(self) -> Dict[str, Any]:
            """Get current cluster configuration"""
            try:
                response = requests.get(
                    f"{SPOT_API_BASE_URL}/cluster/{self.cluster_id}",
                    headers=self.headers
                )
                response.raise_for_status()
                return response.json()
            except requests.exceptions.RequestException as e:
                logger.error(f"Failed to get cluster info: {e}")
                return {}

        def scale_cluster(self, action: str, scale_factor: float = 1.2) -> bool:
            """Scale cluster based on cost optimization flag"""
            try:
                cluster_info = self.get_cluster_info()
                if not cluster_info:
                    return False

                current_capacity = cluster_info.get('response', {}).get('capacity', {})

                if action == 'optimize':
                    # Scale down for cost optimization
                    new_capacity = {
                        'target': max(1, int(current_capacity.get('target', 2) * 0.8)),
                        'minimum': current_capacity.get('minimum', 1),
                        'maximum': current_capacity.get('maximum', 10)
                    }
                    logger.info(f"Scaling down cluster for cost optimization: {new_capacity}")
                else:
                    # Scale up for performance
                    new_capacity = {
                        'target': min(10, int(current_capacity.get('target', 2) * scale_factor)),
                        'minimum': current_capacity.get('minimum', 1),
                        'maximum': current_capacity.get('maximum', 10)
                    }
                    logger.info(f"Scaling up cluster for performance: {new_capacity}")

                response = requests.put(
                    f"{SPOT_API_BASE_URL}/cluster/{self.cluster_id}",
                    headers=self.headers,
                    json={'cluster': {'capacity': new_capacity}}
                )
                response.raise_for_status()
                return True

            except requests.exceptions.RequestException as e:
                logger.error(f"Failed to scale cluster: {e}")
                return False


    def verify_webhook_signature(payload: bytes, signature: str) -> bool:
        """Verify LaunchDarkly webhook signature"""
        if not WEBHOOK_SECRET:
            logger.warning("No webhook secret configured - skipping signature verification")
            return True

        expected_signature = hmac.new(
            WEBHOOK_SECRET.encode('utf-8'),
            payload,
            hashlib.sha256
        ).hexdigest()

        return hmac.compare_digest(signature, expected_signature)


    @app.route('/health', methods=['GET'])
    def health_check():
        """Health check endpoint"""
        return jsonify({
            'status': 'healthy',
            'timestamp': time.time(),
            'version': '0.1.1'
        })


    @app.route('/webhook/launchdarkly', methods=['POST'])
    def handle_launchdarkly_webhook():
        """Handle LaunchDarkly webhook notifications"""
        try:
            # Verify webhook signature
            signature = request.headers.get('X-LD-Signature', '')
            if not verify_webhook_signature(request.data, signature):
                logger.error("Invalid webhook signature")
                return jsonify({'error': 'Invalid signature'}), 401

            # Parse webhook payload
            payload = request.get_json()
            if not payload:
                return jsonify({'error': 'Invalid JSON payload'}), 400

            logger.info(f"Received LaunchDarkly webhook: {payload.get('kind', 'unknown')}")

            # Process flag change events
            if payload.get('kind') == 'flag':
                flag_key = payload.get('data', {}).get('key', '')

                if flag_key == 'enable-cost-optimizer':
                    flag_value = payload.get('data', {}).get('value', False)

                    # Initialize Spot Ocean manager
                    spot_manager = SpotOceanManager(SPOT_API_TOKEN, SPOT_CLUSTER_ID)

                    if flag_value:
                        # Cost optimization enabled - scale down
                        success = spot_manager.scale_cluster('optimize')
                        action = 'cost_optimization_enabled'
                    else:
                        # Cost optimization disabled - scale up
                        success = spot_manager.scale_cluster('performance')
                        action = 'cost_optimization_disabled'

                    logger.info(f"Processed flag change: {action}, success: {success}")

                    return jsonify({
                        'status': 'processed',
                        'action': action,
                        'success': success,
                        'timestamp': time.time()
                    })

            # Default response for other webhook types
            return jsonify({
                'status': 'received',
                'kind': payload.get('kind', 'unknown'),
                'timestamp': time.time()
            })

        except Exception as e:
            logger.error(f"Error processing webhook: {e}")
            return jsonify({'error': 'Internal server error'}), 500


    @app.route('/api/cluster/status', methods=['GET'])
    def get_cluster_status():
        """Get current cluster status"""
        try:
            spot_manager = SpotOceanManager(SPOT_API_TOKEN, SPOT_CLUSTER_ID)
            cluster_info = spot_manager.get_cluster_info()

            return jsonify({
                'cluster_id': SPOT_CLUSTER_ID,
                'status': 'active' if cluster_info else 'unavailable',
                'capacity': cluster_info.get('response', {}).get('capacity', {}),
                'timestamp': time.time()
            })

        except Exception as e:
            logger.error(f"Error getting cluster status: {e}")
            return jsonify({'error': 'Internal server error'}), 500


    if __name__ == '__main__':
        logger.info("Starting OceanSurge Middleware")
        logger.info(f"LaunchDarkly SDK Key configured: {'Yes' if LAUNCHDARKLY_SDK_KEY else 'No'}")
        logger.info(f"Spot API Token configured: {'Yes' if SPOT_API_TOKEN else 'No'}")
        logger.info(f"Spot Cluster ID: {SPOT_CLUSTER_ID}")

        app.run(host='0.0.0.0', port=8000, debug=False)
  requirements.txt: |
    flask==2.3.3
    requests==2.31.0
    gunicorn==21.2.0
    pyyaml==6.0.1
  feature_flags.py: |
    #!/usr/bin/env python3
    """
    Feature Flag Provider Abstraction Layer
    Supports LaunchDarkly and Statsig providers
    """

    import os
    import json
    import logging
    import requests
    import hmac
    import hashlib
    from abc import ABC, abstractmethod
    from typing import Dict, Any, Optional
    from flask import request

    logger = logging.getLogger(__name__)


    class FeatureFlagProvider(ABC):
        """Abstract base class for feature flag providers"""

        @abstractmethod
        def verify_webhook_signature(self, payload: bytes, signature: str) -> bool:
            """Verify webhook signature"""
            pass

        @abstractmethod
        def parse_webhook_payload(self, payload: Dict[str, Any]) -> Optional[Dict[str, Any]]:
            """Parse webhook payload and extract flag information"""
            pass

        @abstractmethod
        def get_webhook_endpoint(self) -> str:
            """Get the webhook endpoint path"""
            pass


    class LaunchDarklyProvider(FeatureFlagProvider):
        """LaunchDarkly feature flag provider"""

        def __init__(self, webhook_secret: str = ""):
            self.webhook_secret = webhook_secret

        def verify_webhook_signature(self, payload: bytes, signature: str) -> bool:
            """Verify LaunchDarkly webhook signature"""
            if not self.webhook_secret:
                logger.warning("No webhook secret configured - skipping signature verification")
                return True

            expected_signature = hmac.new(
                self.webhook_secret.encode('utf-8'),
                payload,
                hashlib.sha256
            ).hexdigest()

            return hmac.compare_digest(signature, expected_signature)

        def parse_webhook_payload(self, payload: Dict[str, Any]) -> Optional[Dict[str, Any]]:
            """Parse LaunchDarkly webhook payload"""
            if payload.get('kind') == 'flag':
                flag_key = payload.get('data', {}).get('key', '')
                if flag_key == 'enable-cost-optimizer':
                    return {
                        'flag_key': flag_key,
                        'flag_value': payload.get('data', {}).get('value', False),
                        'provider': 'launchdarkly'
                    }
            return None

        def get_webhook_endpoint(self) -> str:
            return '/webhook/launchdarkly'


    class StatsigProvider(FeatureFlagProvider):
        """Statsig feature flag provider"""

        def __init__(self, webhook_secret: str = ""):
            self.webhook_secret = webhook_secret

        def verify_webhook_signature(self, payload: bytes, signature: str) -> bool:
            """Verify Statsig webhook signature"""
            if not self.webhook_secret:
                logger.warning("No webhook secret configured - skipping signature verification")
                return True

            expected_signature = hmac.new(
                self.webhook_secret.encode('utf-8'),
                payload,
                hashlib.sha256
            ).hexdigest()

            return hmac.compare_digest(f"sha256={expected_signature}", signature)

        def parse_webhook_payload(self, payload: Dict[str, Any]) -> Optional[Dict[str, Any]]:
            """Parse Statsig webhook payload"""
            if payload.get('event_type') == 'gate_config_updated':
                gate_name = payload.get('data', {}).get('name', '')
                if gate_name == 'enable_cost_optimizer':
                    return {
                        'flag_key': gate_name,
                        'flag_value': payload.get('data', {}).get('enabled', False),
                        'provider': 'statsig'
                    }
            return None

        def get_webhook_endpoint(self) -> str:
            return '/webhook/statsig'


    class FeatureFlagManager:
        """Manages feature flag providers and routing"""

        def __init__(self, provider_type: str):
            self.provider_type = provider_type.lower()
            webhook_secret = os.getenv('WEBHOOK_SECRET', '')

            if self.provider_type == 'launchdarkly':
                self.provider = LaunchDarklyProvider(webhook_secret)
            elif self.provider_type == 'statsig':
                self.provider = StatsigProvider(webhook_secret)
            else:
                raise ValueError(f"Unsupported provider type: {provider_type}")

        def get_provider(self) -> FeatureFlagProvider:
            """Get the current provider instance"""
            return self.provider

        def get_provider_type(self) -> str:
            """Get the provider type"""
            return self.provider_type
  logging_providers.py: |
    #!/usr/bin/env python3
    """
    Logging Provider Abstraction Layer
    Supports LaunchDarkly and Statsig for logging feature flag events and metrics
    """

    import os
    import json
    import logging
    import requests
    import time
    from abc import ABC, abstractmethod
    from typing import Dict, Any, Optional, List
    from datetime import datetime, timezone

    logger = logging.getLogger(__name__)


    class LoggingProvider(ABC):
        """Abstract base class for logging providers"""

        @abstractmethod
        def log_flag_evaluation(self, flag_key: str, flag_value: Any, user_context: Optional[Dict] = None, metadata: Optional[Dict] = None) -> bool:
            """Log a feature flag evaluation event"""
            pass

        @abstractmethod
        def log_webhook_event(self, event_type: str, payload: Dict[str, Any], response_status: int, metadata: Optional[Dict] = None) -> bool:
            """Log a webhook event"""
            pass

        @abstractmethod
        def log_cluster_action(self, action: str, cluster_id: str, success: bool, details: Optional[Dict] = None) -> bool:
            """Log a cluster scaling action"""
            pass

        @abstractmethod
        def log_custom_event(self, event_name: str, properties: Dict[str, Any]) -> bool:
            """Log a custom event"""
            pass

        @abstractmethod
        def flush_events(self) -> bool:
            """Flush any pending events"""
            pass


    class LaunchDarklyLoggingProvider(LoggingProvider):
        """LaunchDarkly logging provider using Events API"""

        def __init__(self, sdk_key: str):
            self.sdk_key = sdk_key
            self.events_url = "https://events.launchdarkly.com/bulk"
            self.headers = {
                'Authorization': sdk_key,
                'Content-Type': 'application/json',
                'User-Agent': 'Storm-Surge-Middleware/1.0'
            }
            self.pending_events = []
            self.max_batch_size = 100

        def _create_user_context(self, user_context: Optional[Dict] = None) -> Dict[str, Any]:
            """Create LaunchDarkly user context"""
            default_context = {
                "key": "storm-surge-middleware",
                "kind": "user",
                "name": "Storm Surge Middleware",
                "custom": {
                    "service": "ocean-surge-middleware",
                    "version": "1.0.1"
                }
            }

            if user_context:
                default_context["custom"].update(user_context)

            return default_context

        def log_flag_evaluation(self, flag_key: str, flag_value: Any, user_context: Optional[Dict] = None, metadata: Optional[Dict] = None) -> bool:
            """Log a feature flag evaluation event to LaunchDarkly"""
            try:
                event = {
                    "kind": "feature",
                    "creationDate": int(time.time() * 1000),
                    "key": flag_key,
                    "value": flag_value,
                    "default": False,
                    "user": self._create_user_context(user_context),
                    "version": 1
                }

                if metadata:
                    event["custom"] = metadata

                self.pending_events.append(event)

                if len(self.pending_events) >= self.max_batch_size:
                    return self.flush_events()

                return True

            except Exception as e:
                logger.error(f"Failed to log flag evaluation to LaunchDarkly: {e}")
                return False

        def log_webhook_event(self, event_type: str, payload: Dict[str, Any], response_status: int, metadata: Optional[Dict] = None) -> bool:
            """Log a webhook event as a custom event"""
            properties = {
                "event_type": event_type,
                "response_status": response_status,
                "payload_size": len(json.dumps(payload)),
                "timestamp": datetime.now(timezone.utc).isoformat()
            }

            if metadata:
                properties.update(metadata)

            return self.log_custom_event("webhook_received", properties)

        def log_cluster_action(self, action: str, cluster_id: str, success: bool, details: Optional[Dict] = None) -> bool:
            """Log a cluster scaling action"""
            properties = {
                "action": action,
                "cluster_id": cluster_id,
                "success": success,
                "timestamp": datetime.now(timezone.utc).isoformat()
            }

            if details:
                properties.update(details)

            return self.log_custom_event("cluster_action", properties)

        def log_custom_event(self, event_name: str, properties: Dict[str, Any]) -> bool:
            """Log a custom event to LaunchDarkly"""
            try:
                event = {
                    "kind": "custom",
                    "creationDate": int(time.time() * 1000),
                    "key": event_name,
                    "user": self._create_user_context(),
                    "data": properties
                }

                self.pending_events.append(event)

                if len(self.pending_events) >= self.max_batch_size:
                    return self.flush_events()

                return True

            except Exception as e:
                logger.error(f"Failed to log custom event to LaunchDarkly: {e}")
                return False

        def flush_events(self) -> bool:
            """Flush pending events to LaunchDarkly"""
            if not self.pending_events:
                return True

            try:
                response = requests.post(
                    self.events_url,
                    headers=self.headers,
                    json=self.pending_events,
                    timeout=10
                )

                if response.status_code in [200, 202]:
                    logger.info(f"Successfully sent {len(self.pending_events)} events to LaunchDarkly")
                    self.pending_events.clear()
                    return True
                else:
                    logger.error(f"Failed to send events to LaunchDarkly: {response.status_code} - {response.text}")
                    return False

            except Exception as e:
                logger.error(f"Failed to flush events to LaunchDarkly: {e}")
                return False


    class StatsigLoggingProvider(LoggingProvider):
        """Statsig logging provider using Events API"""

        def __init__(self, server_key: str):
            self.server_key = server_key
            self.events_url = "https://statsigapi.net/v1/log_event"
            self.headers = {
                'STATSIG-API-KEY': server_key,
                'Content-Type': 'application/json',
                'User-Agent': 'Storm-Surge-Middleware/1.0'
            }
            self.pending_events = []
            self.max_batch_size = 100

        def _create_user_context(self, user_context: Optional[Dict] = None) -> Dict[str, Any]:
            """Create Statsig user context"""
            default_context = {
                "userID": "storm-surge-middleware",
                "email": "middleware@oceansurge.com",
                "custom": {
                    "service": "ocean-surge-middleware",
                    "version": "1.0.1"
                }
            }

            if user_context:
                default_context["custom"].update(user_context)

            return default_context

        def log_flag_evaluation(self, flag_key: str, flag_value: Any, user_context: Optional[Dict] = None, metadata: Optional[Dict] = None) -> bool:
            """Log a feature flag evaluation event to Statsig"""
            try:
                event = {
                    "eventName": "gate_evaluation",
                    "user": self._create_user_context(user_context),
                    "time": int(time.time() * 1000),
                    "metadata": {
                        "gate_name": flag_key,
                        "gate_value": flag_value,
                        "source": "storm_surge_middleware"
                    }
                }

                if metadata:
                    event["metadata"].update(metadata)

                self.pending_events.append(event)

                if len(self.pending_events) >= self.max_batch_size:
                    return self.flush_events()

                return True

            except Exception as e:
                logger.error(f"Failed to log flag evaluation to Statsig: {e}")
                return False

        def log_webhook_event(self, event_type: str, payload: Dict[str, Any], response_status: int, metadata: Optional[Dict] = None) -> bool:
            """Log a webhook event"""
            properties = {
                "event_type": event_type,
                "response_status": response_status,
                "payload_size": len(json.dumps(payload)),
                "timestamp": datetime.now(timezone.utc).isoformat()
            }

            if metadata:
                properties.update(metadata)

            return self.log_custom_event("webhook_received", properties)

        def log_cluster_action(self, action: str, cluster_id: str, success: bool, details: Optional[Dict] = None) -> bool:
            """Log a cluster scaling action"""
            properties = {
                "action": action,
                "cluster_id": cluster_id,
                "success": success,
                "timestamp": datetime.now(timezone.utc).isoformat()
            }

            if details:
                properties.update(details)

            return self.log_custom_event("cluster_action", properties)

        def log_custom_event(self, event_name: str, properties: Dict[str, Any]) -> bool:
            """Log a custom event to Statsig"""
            try:
                event = {
                    "eventName": event_name,
                    "user": self._create_user_context(),
                    "time": int(time.time() * 1000),
                    "metadata": properties
                }

                self.pending_events.append(event)

                if len(self.pending_events) >= self.max_batch_size:
                    return self.flush_events()

                return True

            except Exception as e:
                logger.error(f"Failed to log custom event to Statsig: {e}")
                return False

        def flush_events(self) -> bool:
            """Flush pending events to Statsig"""
            if not self.pending_events:
                return True

            try:
                payload = {
                    "events": self.pending_events,
                    "statsigMetadata": {
                        "sdkType": "storm-surge-middleware",
                        "sdkVersion": "1.0.1"
                    }
                }

                response = requests.post(
                    self.events_url,
                    headers=self.headers,
                    json=payload,
                    timeout=10
                )

                if response.status_code in [200, 202]:
                    logger.info(f"Successfully sent {len(self.pending_events)} events to Statsig")
                    self.pending_events.clear()
                    return True
                else:
                    logger.error(f"Failed to send events to Statsig: {response.status_code} - {response.text}")
                    return False

            except Exception as e:
                logger.error(f"Failed to flush events to Statsig: {e}")
                return False


    class LoggingManager:
        """Manages logging providers"""

        def __init__(self, provider_type: str, feature_flag_provider_type: str):
            self.provider_type = provider_type.lower()
            self.feature_flag_provider_type = feature_flag_provider_type.lower()
            self.provider = None

            # Initialize logging provider based on type
            if self.provider_type == 'launchdarkly':
                sdk_key = os.getenv('LAUNCHDARKLY_SDK_KEY', '')
                if sdk_key:
                    self.provider = LaunchDarklyLoggingProvider(sdk_key)
                else:
                    logger.warning("LaunchDarkly SDK key not provided for logging")

            elif self.provider_type == 'statsig':
                server_key = os.getenv('STATSIG_SERVER_KEY', '')
                if server_key:
                    self.provider = StatsigLoggingProvider(server_key)
                else:
                    logger.warning("Statsig server key not provided for logging")

            elif self.provider_type == 'auto':
                # Auto-detect based on feature flag provider
                if self.feature_flag_provider_type == 'launchdarkly':
                    sdk_key = os.getenv('LAUNCHDARKLY_SDK_KEY', '')
                    if sdk_key:
                        self.provider = LaunchDarklyLoggingProvider(sdk_key)
                        self.provider_type = 'launchdarkly'
                elif self.feature_flag_provider_type == 'statsig':
                    server_key = os.getenv('STATSIG_SERVER_KEY', '')
                    if server_key:
                        self.provider = StatsigLoggingProvider(server_key)
                        self.provider_type = 'statsig'

            elif self.provider_type == 'disabled':
                logger.info("Logging provider disabled")

            else:
                logger.warning(f"Unknown logging provider type: {provider_type}")

        def get_provider(self) -> Optional[LoggingProvider]:
            """Get the current logging provider instance"""
            return self.provider

        def get_provider_type(self) -> str:
            """Get the logging provider type"""
            return self.provider_type

        def log_flag_evaluation(self, flag_key: str, flag_value: Any, user_context: Optional[Dict] = None, metadata: Optional[Dict] = None) -> bool:
            """Log flag evaluation if provider is available"""
            if self.provider:
                return self.provider.log_flag_evaluation(flag_key, flag_value, user_context, metadata)
            return True

        def log_webhook_event(self, event_type: str, payload: Dict[str, Any], response_status: int, metadata: Optional[Dict] = None) -> bool:
            """Log webhook event if provider is available"""
            if self.provider:
                return self.provider.log_webhook_event(event_type, payload, response_status, metadata)
            return True

        def log_cluster_action(self, action: str, cluster_id: str, success: bool, details: Optional[Dict] = None) -> bool:
            """Log cluster action if provider is available"""
            if self.provider:
                return self.provider.log_cluster_action(action, cluster_id, success, details)
            return True

        def log_custom_event(self, event_name: str, properties: Dict[str, Any]) -> bool:
            """Log custom event if provider is available"""
            if self.provider:
                return self.provider.log_custom_event(event_name, properties)
            return True

        def flush_events(self) -> bool:
            """Flush pending events if provider is available"""
            if self.provider:
                return self.provider.flush_events()
            return True
